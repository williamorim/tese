%% ------------------------------------------------------------------------- %%
\chapter{Outras técnicas de aprendizado estatístico}
\label{cap:aprendizado_estatistico}

\begin{flushright}
	\textcolor{gray}{
		\begin{tabular}{r}
			There are no routine statistical questions, \\
			only questionable statistical routines. \\
			--- Sir David Cox			
		\end{tabular} 
	}
	\vspace{5mm}
\end{flushright}

No Capítulo anterior, discutimos diversas classes de modelos úteis para o ajuste de séries temporais dentro do contexto de poluição do ar. A escolha do modelo, e tudo que envolve essa tarefa, faz parte de um \textit{framework} maior, muitas vezes chamado de \textit{aprendizado estatístico}. O aprendizado estatístico pode ser definido como um conjunto de técnicas utilizadas para extrair informação dos dados. Assim, além da modelagem, também podemos incluir a análise exploratória, discutida no Capítulo \ref{cap:analise-exploratoria}, e as ferramentas que sugerem se o modelo ajustado é ou não uma boa escolha para representar o fenômeno sob estudo. Essas técnicas serão o tema deste Capítulo.

Mais precisamente, discutiremos métodos de reamostragem, seleção de variáveis e regularização. Os métodos de reamostragem geralmente são utilizados para avaliar a performance de um modelo ou prover medidas de acurácia para as estimativas dos parâmetros. Dada uma classe de modelos, os métodos de seleção de variáveis e regularização permitem aumentarmos o poder preditivo e a interpretabilidade do modelo.

\section{Métodos de reamostragem}

- Introdução

	- O que é?
	
	- Para que serve?
	
- Falaremos de validação cruzada e bootstrap

\subsection{Validação cruzada}

Uma forma de avaliar a qualidade do ajuste de um modelo é observar o seu \textit{erro de teste}. O erro de teste é o erro médio resultante da utilização do modelo escolhido para prever a resposta em novas observações, que não foram utilizadas para estimar os parâmetros do modelo \citep{James2013}.

Como na maioria dos estudos não é possível obter facilmente novas observações, podemos calcular o erro de teste dividindo a amostra principal em duas partes: uma utilizada para o ajuste do modelo e a outra para o cálculo do erro de teste, como se fosse um conjunto de novas observações. Essa técnica é conhecida como \textit{validação cruzada} \citep{James2013}. Há diversos tipos de validação cruzada, que variam a depender da forma utilizada para dividir a amostra. Nesta seção, apresentaremos os principais tipos de validação cruzada e discutiremos as vantagens e desvantagens de cada uma.

|%Quando precisamos escolher valores para hiperparâmetros do modelo, como o grau de suavização de um modelo aditivo generalizado (Seção \ref{sec:gam}) ou o $\lambda$ do LASSO (Seção \ref{sec:lasso}), podemos dividir a amostra em ainda mais uma parte: uma amostra de validação. Nesses casos, os modelos são treinados com a amostra de teste e, para diversos valores do hiperparâmetro, calculamos o erro de teste na amostra de validação. Escolhemos então o hiperparâmetro com menor erro de teste e utilizamos a amostra de teste para calcular o erro de teste do modelo final. Repare que a amostra de teste nunca é utilizada para ajustar o modelo.



\subsubsection{Amostra de validação}

A amostra de validação é a forma mais simples de validação cruzada. A estratégia aqui consiste em dividir aleatoriamente as observações em uma amostra de treino e uma amostra de validação. A proporção de observações em cada uma depende do tamanho amostral. Costuma-se utilizar 30\% da amostra para validação, mas esse número pode ser menor em amostras muito grandes (mais de 100 mil observações, por exemplo).

Conforme discutido em \cite{James2013}, a amostra de validação tem duas desvantagens em potencial:

\begin{itemize}
	\item a estimativa do erro de teste pode ter alta variância, dependendo de quais observações ficaram na amostra de treino e quais fiaram na amostra de validação;
	\item como a acurácia de modelos estatísticos é menor quando ajustados com menos observações e apenas parte das observações são utilizadas no modelo final, a estimativa do erro de teste pode superestimada. 
\end{itemize}

A seguir, apresentamos um tipo de validação cruzada que não possui essas limitações.

\subsubsection{LOOCV}

Considere uma amostra com $n$ observações. A validação cruzada \textit{leave-one-out} (LOOCV) consiste em rodar o modelo escolhido $n$ vezes, sendo que em cada ajuste nós deixamos a $i$-ésima observação de fora, $i = 1, \dots, n$, e a utilizamos para calcular o erro de teste. A estimativa final do erro de teste será então a média das $n$ estimativas parciais. 


\begin{figure}[h!]
	\centering
	\includegraphics[width=0.8\linewidth]{figuras/cap-aprend-estat-loocv.png}
	\caption{Esquematização da validação cruzada \textit{leave-one-out}.}
	\label{cap-aprend-estat-loocv}
\end{figure}

Repare que com essa estratégia, todas as observações são utilizadas no ajuste do modelo, o que elimina as limitações da amostra de validação. No entanto, uma desvantagem aqui é a necessidade de ajustar o modelo $n$ vezes. Quando $n$ é muito grande, a LOOCV pode exigir um alto tempo de computação. Apresentamos a seguir uma generalização do LOOCV que é mais adequada para grandes amostras.

\subsubsection{K-fold}

Podemos generalizar a LOOCV dividindo a amostra em $k$ grupos com aproximadamente a mesma quantidade de observações e então ajustando o modelo $k$ vezes, sendo que em cada ajuste selecionamos um grupo diferente como amostra de validação. Essa abordagem é chamada de \textit{validação cruzada k-fold}. Note que a LOOCV é o caso especial em que $k = n$.

A maior vantagem da validação cruzada \textit{k-fold} sobre a LOOCV é computacional. Em vez de ajustarmos o modelo $n$ vezes, ajustamos apenas $k$, sendo que $k << n$. E como estamos utilizando todas as observações para treinar o modelo, não temos as limitações de se utilizar uma única amostra de validação.

Muitas vezes, quando a classe de modelos escolhida exige a escolha de hiperparâmetros, como o grau de suavização de um modelo aditivo generalizado (Seção \ref{sec:gam}) ou o $\lambda$ do LASSO (Seção \ref{sec:lasso}), é comum separarmos a amostra em três partes: uma amostra de treino, uma amostra de validação e uma amostra de teste. Nesse caso, os modelos são treinados com a amostra de treino e, para diversos valores do hiperparâmetro, calculamos o erro de teste na amostra de validação. Escolhemos então o hiperparâmetro que leva ao menor erro de teste e utilizamos a amostra de teste para calcular o erro de teste do modelo final. Geralmente utiliza-se LOOOCV ou \textit{k-fold} para a validação e uma amostra separada para o teste. Essa estratégia é utilizada para garantir que o erro de teste não seja calculado em observações utilizadas no ajuste do modelo e reflita o erro que obteríamos ao aplicá-lo no mundo real.

Como discutimos até agora, a validação cruzada utiliza reamostragem para avaliar a qualidade do ajuste realizado. A seguir, apresentaremos uma técnica de reamostragem para obter informações sobre as estimativas do modelo.

\subsection{Bootstrap}

\textit{Bootstrap} é uma poderosa ferramenta estatística utilizada para quantificar incertezas associadas a estimadores e modelos estatísticos. \cite{Salvo2014} e \cite{Salvo2017}, por exemplo, utilizaram essa técnica para estimar o erro-padrão dos coeficientes do modelo de regressão linear ajustado para associar a concentração de ozônio na cidade de São Paulo com a proporção estimada de veículos bicombustíveis rodando a gasolina. Segundo os autores, o bootstrap foi utilizado para contemplar a variação causada pelo erro de medida presente na estimação da proporção de carros rodando a gasolina e na medição das condições climáticas.

O bootstrap consiste em gerar novas amostras sorteando repetidamente novas observações do conjunto de dados original. Para cada amostra, podemos ajustar o modelo escolhido, obtendo assim uma amostra dos coeficientes. A estimativa de bootstrap do erro-padrão de cada coeficiente, por exemplo, é dada pelo desvio-padrão das estimativas obtidas.

Mais informações sobre o bootstrap podem ser encontradas em \cite{James2013}.

%Essa técnica pode ser utilizada, por exemplo, para estimar o erro-padrão dos coeficientes de um modelo de regressão.

\section{Seleção de modelos e regularização}

\subsection{Seleção de variáveis}



\subsection{Regressão ridge}
\label{sec:ridge}


\subsection{LASSO}
\label{sec:lasso}